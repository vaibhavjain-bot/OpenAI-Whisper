{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "0.13.1+cu117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vaibh\\anaconda3\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "import torch\n",
    "import torchaudio\n",
    "#check the version of torch\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "import datetime\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2080 SUPER (UUID: GPU-c608f8ac-6c15-ea89-3a18-b1c5568c2796)\n"
     ]
    }
   ],
   "source": [
    "#check if gpu is available\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing whisper model\n",
    "model = whisper.load_model('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_video_url = \"https://youtu.be/qTgPSKKjfVg\"\n",
    "youtube_video = YouTube(youtube_video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Stream: itag=\"17\" mime_type=\"video/3gpp\" res=\"144p\" fps=\"12fps\" vcodec=\"mp4v.20.3\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">\n",
      "<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"24fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">\n",
      "<Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"24fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">\n",
      "<Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"24fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"24fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"24fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"24fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"24fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"24fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"24fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"24fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"24fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"24fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"24fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"24fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">\n",
      "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n",
      "<Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">\n"
     ]
    }
   ],
   "source": [
    "#loop to check for avaible video and audio streams\n",
    "for stream in youtube_video.streams:\n",
    "  print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering out only audio streams and creating variable strea\n",
    "streams = youtube_video.streams.filter(only_audio=True)\n",
    "streams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the variable stream equal to the first audio file\n",
    "stream = streams.first()\n",
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\vaibh\\\\Documents\\\\GitHub\\\\YT-Transcribe\\\\DALLE2.mp4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downaloding the audio file\n",
    "stream.download(filename=\"DALLE2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at 2023-01-22 09:36:30.582429\n",
      "ended at 2023-01-22 09:37:01.135883\n",
      "time elapsed: 0:00:30.553454\n"
     ]
    }
   ],
   "source": [
    "# save a timestamp before transcription\n",
    "t1 = datetime.datetime.now()\n",
    "print(f\"started at {t1}\")\n",
    "\n",
    "# do the transcription\n",
    "output = model.transcribe(\"DALLE2.MP4\")\n",
    "\n",
    "# show time elapsed after transcription is complete.\n",
    "t2 = datetime.datetime.now()\n",
    "print(f\"ended at {t2}\")\n",
    "print(f\"time elapsed: {t2 - t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Have you ever seen a polar bear playing bass? Or a robot painted like a Picasso? Didn't think so. Dolly2 is a new AI system from OpenAI that can take simple text descriptions like a koala dunking a basketball and turn them into photo-realistic images that have never existed before. Dolly2 can also realistically edit and retouch photos. Based on a simple natural language description, it can fill in or replace part of an image with AI-generated imagery that blends seamlessly with the original. It's called in-painting. In January 2021, OpenAI introduced Dolly, a system that could generate images from text, like this avocado armchair. Dolly2 takes the technology even further with higher resolution, greater comprehension, and new capabilities, like in-painting. It can even start with an image as an input and create variations with different angles and styles. Dolly was created by training a neural network on images and their text descriptions. Through deep learning, it not only understands individual objects, like koala bears and motorcycles, but learns from relationships between objects. And when you ask Dolly for an image of a koala bear riding a motorcycle, it knows how to create that or anything else with a relationship to another object or action. The Dolly research has three main outcomes. First, it can help people express themselves visually in ways they may not have been able to before. Second, an AI-generated image can tell us a lot about whether the system understands us or is just repeating what it's been taught. Third, Dolly helps humans understand how AI systems see and understand our world. This is a critical part of developing AI that's useful and safe. The technology is constantly evolving, and Dolly2 has limitations. If it's taught with images that are incorrectly labeled, like a plane labeled car, and a user tries to generate a car, Dolly may create a plane. It's like talking to a person who learned the wrong word for something. Dolly can also be limited by gaps in its training. If you type baboon and Dolly has learned what a baboon is through images and accurate labels, it will generate a lot of great baboons. But if you type howler monkey and it hasn't learned what a howler monkey is, Dolly will give you its best idea of what it thinks it could be, like a howling monkey. What's exciting about their approach used to train Dolly is that it can take what it learned from a variety of other labeled images and then apply it to a new image. Given a picture of a monkey, Dolly can infer what it would look like doing something it's never done before, like paying its taxes while wearing a funny hat. Dolly is an example of how imaginative humans and clever systems can work together to make new things, amplifying our creative potential.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as f:\n",
    "   # Convert the dictionary to a JSON string and write it to the file\n",
    "   data = {'key': output['text']}\n",
    "   json_data = json.dumps(data)\n",
    "   f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key=\"\"\"Insert openai API key\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"key\": \" Have you ever seen a polar bear playing bass? Or a robot painted like a Picasso? Didn't think so. Dolly2 is a new AI system from OpenAI that can take simple text descriptions like a koala dunking a basketball and turn them into photo-realistic images that have never existed before. Dolly2 can also realistically edit and retouch photos. Based on a simple natural language description, it can fill in or replace part of an image with AI-generated imagery that blends seamlessly with the original. It's called in-painting. In January 2021, OpenAI introduced Dolly, a system that could generate images from text, like this avocado armchair. Dolly2 takes the technology even further with higher resolution, greater comprehension, and new capabilities, like in-painting. It can even start with an image as an input and create variations with different angles and styles. Dolly was created by training a neural network on images and their text descriptions. Through deep learning, it not only understands individual objects, like koala bears and motorcycles, but learns from relationships between objects. And when you ask Dolly for an image of a koala bear riding a motorcycle, it knows how to create that or anything else with a relationship to another object or action. The Dolly research has three main outcomes. First, it can help people express themselves visually in ways they may not have been able to before. Second, an AI-generated image can tell us a lot about whether the system understands us or is just repeating what it's been taught. Third, Dolly helps humans understand how AI systems see and understand our world. This is a critical part of developing AI that's useful and safe. The technology is constantly evolving, and Dolly2 has limitations. If it's taught with images that are incorrectly labeled, like a plane labeled car, and a user tries to generate a car, Dolly may create a plane. It's like talking to a person who learned the wrong word for something. Dolly can also be limited by gaps in its training. If you type baboon and Dolly has learned what a baboon is through images and accurate labels, it will generate a lot of great baboons. But if you type howler monkey and it hasn't learned what a howler monkey is, Dolly will give you its best idea of what it thinks it could be, like a howling monkey. What's exciting about their approach used to train Dolly is that it can take what it learned from a variety of other labeled images and then apply it to a new image. Given a picture of a monkey, Dolly can infer what it would look like doing something it's never done before, like paying its taxes while wearing a funny hat. Dolly is an example of how imaginative humans and clever systems can work together to make new things, amplifying our creative potential.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('output.txt', 'r') as f:\n",
    "    # Read the contents of the file into a string\n",
    "    prompt = f.read()\n",
    "    \n",
    "    # Print the contents of the file\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"key\": \" Have you ever seen a polar bear playing bass? Or a robot painted like a Picasso? Didn\\'t think so. Dolly2 is a new AI system from OpenAI that can take simple text descriptions like a koala dunking a basketball and turn them into photo-realistic images that have never existed before. Dolly2 can also realistically edit and retouch photos. Based on a simple natural language description, it can fill in or replace part of an image with AI-generated imagery that blends seamlessly with the original. It\\'s called in-painting. In January 2021, OpenAI introduced Dolly, a system that could generate images from text, like this avocado armchair. Dolly2 takes the technology even further with higher resolution, greater comprehension, and new capabilities, like in-painting. It can even start with an image as an input and create variations with different angles and styles. Dolly was created by training a neural network on images and their text descriptions. Through deep learning, it not only understands individual objects, like koala bears and motorcycles, but learns from relationships between objects. And when you ask Dolly for an image of a koala bear riding a motorcycle, it knows how to create that or anything else with a relationship to another object or action. The Dolly research has three main outcomes. First, it can help people express themselves visually in ways they may not have been able to before. Second, an AI-generated image can tell us a lot about whether the system understands us or is just repeating what it\\'s been taught. Third, Dolly helps humans understand how AI systems see and understand our world. This is a critical part of developing AI that\\'s useful and safe. The technology is constantly evolving, and Dolly2 has limitations. If it\\'s taught with images that are incorrectly labeled, like a plane labeled car, and a user tries to generate a car, Dolly may create a plane. It\\'s like talking to a person who learned the wrong word for something. Dolly can also be limited by gaps in its training. If you type baboon and Dolly has learned what a baboon is through images and accurate labels, it will generate a lot of great baboons. But if you type howler monkey and it hasn\\'t learned what a howler monkey is, Dolly will give you its best idea of what it thinks it could be, like a howling monkey. What\\'s exciting about their approach used to train Dolly is that it can take what it learned from a variety of other labeled images and then apply it to a new image. Given a picture of a monkey, Dolly can infer what it would look like doing something it\\'s never done before, like paying its taxes while wearing a funny hat. Dolly is an example of how imaginative humans and clever systems can work together to make new things, amplifying our creative potential.\"}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"key\": \" Have you ever seen a polar bear playing bass? Or a robot painted like a Picasso? Didn't think so. Dolly2 is a new AI system from OpenAI that can take simple text descriptions like a koala dunking a basketball and turn them into photo-realistic images that have never existed before. Dolly2 can also realistically edit and retouch photos. Based on a simple natural language description, it can fill in or replace part of an image with AI-generated imagery that blends seamlessly with the original. It's called in-painting. In January 2021, OpenAI introduced Dolly, a system that could generate images from text, like this avocado armchair. Dolly2 takes the technology even further with higher resolution, greater comprehension, and new capabilities, like in-painting. It can even start with an image as an input and create variations with different angles and styles. Dolly was created by training a neural network on images and their text descriptions. Through deep learning, it not only understands individual objects, like koala bears and motorcycles, but learns from relationships between objects. And when you ask Dolly for an image of a koala bear riding a motorcycle, it knows how to create that or anything else with a relationship to another object or action. The Dolly research has three main outcomes. First, it can help people express themselves visually in ways they may not have been able to before. Second, an AI-generated image can tell us a lot about whether the system understands us or is just repeating what it's been taught. Third, Dolly helps humans understand how AI systems see and understand our world. This is a critical part of developing AI that's useful and safe. The technology is constantly evolving, and Dolly2 has limitations. If it's taught with images that are incorrectly labeled, like a plane labeled car, and a user tries to generate a car, Dolly may create a plane. It's like talking to a person who learned the wrong word for something. Dolly can also be limited by gaps in its training. If you type baboon and Dolly has learned what a baboon is through images and accurate labels, it will generate a lot of great baboons. But if you type howler monkey and it hasn't learned what a howler monkey is, Dolly will give you its best idea of what it thinks it could be, like a howling monkey. What's exciting about their approach used to train Dolly is that it can take what it learned from a variety of other labeled images and then apply it to a new image. Given a picture of a monkey, Dolly can infer what it would look like doing something it's never done before, like paying its taxes while wearing a funny hat. Dolly is an example of how imaginative humans and clever systems can work together to make new things, amplifying our creative potential.\"}\n"
     ]
    }
   ],
   "source": [
    "# Open the file for reading\n",
    "with open('output.txt', 'r') as f:\n",
    "    # Read the contents of the file into a string\n",
    "    contents = f.read()\n",
    "    \n",
    "    # Print the contents of the file\n",
    "    print(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"key\":',\n",
       " '\"',\n",
       " 'Have',\n",
       " 'you',\n",
       " 'ever',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'polar',\n",
       " 'bear',\n",
       " 'playing',\n",
       " 'bass?',\n",
       " 'Or',\n",
       " 'a',\n",
       " 'robot',\n",
       " 'painted',\n",
       " 'like',\n",
       " 'a',\n",
       " 'Picasso?',\n",
       " \"Didn't\",\n",
       " 'think']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = contents.split(\" \")\n",
    "\n",
    "# show the first 20 words\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['{\"key\":', '\"', 'Have', 'you', 'ever', 'seen', 'a', 'polar',\n",
       "        'bear', 'playing', 'bass?', 'Or', 'a', 'robot', 'painted', 'like',\n",
       "        'a', 'Picasso?', \"Didn't\", 'think', 'so.', 'Dolly2', 'is', 'a',\n",
       "        'new', 'AI', 'system', 'from', 'OpenAI', 'that', 'can', 'take',\n",
       "        'simple', 'text', 'descriptions', 'like', 'a', 'koala', 'dunking',\n",
       "        'a', 'basketball', 'and', 'turn', 'them', 'into',\n",
       "        'photo-realistic', 'images', 'that', 'have', 'never', 'existed',\n",
       "        'before.', 'Dolly2', 'can', 'also', 'realistically', 'edit', 'and',\n",
       "        'retouch', 'photos.', 'Based', 'on', 'a', 'simple', 'natural',\n",
       "        'language', 'description,', 'it', 'can', 'fill', 'in', 'or',\n",
       "        'replace', 'part', 'of', 'an', 'image', 'with', 'AI-generated',\n",
       "        'imagery'], dtype='<U15'),\n",
       " array(['that', 'blends', 'seamlessly', 'with', 'the', 'original.', \"It's\",\n",
       "        'called', 'in-painting.', 'In', 'January', '2021,', 'OpenAI',\n",
       "        'introduced', 'Dolly,', 'a', 'system', 'that', 'could', 'generate',\n",
       "        'images', 'from', 'text,', 'like', 'this', 'avocado', 'armchair.',\n",
       "        'Dolly2', 'takes', 'the', 'technology', 'even', 'further', 'with',\n",
       "        'higher', 'resolution,', 'greater', 'comprehension,', 'and', 'new',\n",
       "        'capabilities,', 'like', 'in-painting.', 'It', 'can', 'even',\n",
       "        'start', 'with', 'an', 'image', 'as', 'an', 'input', 'and',\n",
       "        'create', 'variations', 'with', 'different', 'angles', 'and',\n",
       "        'styles.', 'Dolly', 'was', 'created', 'by', 'training', 'a',\n",
       "        'neural', 'network', 'on', 'images', 'and', 'their', 'text',\n",
       "        'descriptions.', 'Through', 'deep', 'learning,', 'it', 'not'],\n",
       "       dtype='<U15'),\n",
       " array(['only', 'understands', 'individual', 'objects,', 'like', 'koala',\n",
       "        'bears', 'and', 'motorcycles,', 'but', 'learns', 'from',\n",
       "        'relationships', 'between', 'objects.', 'And', 'when', 'you',\n",
       "        'ask', 'Dolly', 'for', 'an', 'image', 'of', 'a', 'koala', 'bear',\n",
       "        'riding', 'a', 'motorcycle,', 'it', 'knows', 'how', 'to', 'create',\n",
       "        'that', 'or', 'anything', 'else', 'with', 'a', 'relationship',\n",
       "        'to', 'another', 'object', 'or', 'action.', 'The', 'Dolly',\n",
       "        'research', 'has', 'three', 'main', 'outcomes.', 'First,', 'it',\n",
       "        'can', 'help', 'people', 'express', 'themselves', 'visually', 'in',\n",
       "        'ways', 'they', 'may', 'not', 'have', 'been', 'able', 'to',\n",
       "        'before.', 'Second,', 'an', 'AI-generated', 'image', 'can', 'tell',\n",
       "        'us', 'a'], dtype='<U15'),\n",
       " array(['lot', 'about', 'whether', 'the', 'system', 'understands', 'us',\n",
       "        'or', 'is', 'just', 'repeating', 'what', \"it's\", 'been', 'taught.',\n",
       "        'Third,', 'Dolly', 'helps', 'humans', 'understand', 'how', 'AI',\n",
       "        'systems', 'see', 'and', 'understand', 'our', 'world.', 'This',\n",
       "        'is', 'a', 'critical', 'part', 'of', 'developing', 'AI', \"that's\",\n",
       "        'useful', 'and', 'safe.', 'The', 'technology', 'is', 'constantly',\n",
       "        'evolving,', 'and', 'Dolly2', 'has', 'limitations.', 'If', \"it's\",\n",
       "        'taught', 'with', 'images', 'that', 'are', 'incorrectly',\n",
       "        'labeled,', 'like', 'a', 'plane', 'labeled', 'car,', 'and', 'a',\n",
       "        'user', 'tries', 'to', 'generate', 'a', 'car,', 'Dolly', 'may',\n",
       "        'create', 'a', 'plane.', \"It's\", 'like', 'talking', 'to'],\n",
       "       dtype='<U15'),\n",
       " array(['a', 'person', 'who', 'learned', 'the', 'wrong', 'word', 'for',\n",
       "        'something.', 'Dolly', 'can', 'also', 'be', 'limited', 'by',\n",
       "        'gaps', 'in', 'its', 'training.', 'If', 'you', 'type', 'baboon',\n",
       "        'and', 'Dolly', 'has', 'learned', 'what', 'a', 'baboon', 'is',\n",
       "        'through', 'images', 'and', 'accurate', 'labels,', 'it', 'will',\n",
       "        'generate', 'a', 'lot', 'of', 'great', 'baboons.', 'But', 'if',\n",
       "        'you', 'type', 'howler', 'monkey', 'and', 'it', \"hasn't\",\n",
       "        'learned', 'what', 'a', 'howler', 'monkey', 'is,', 'Dolly', 'will',\n",
       "        'give', 'you', 'its', 'best', 'idea', 'of', 'what', 'it', 'thinks',\n",
       "        'it', 'could', 'be,', 'like', 'a', 'howling', 'monkey.', \"What's\",\n",
       "        'exciting', 'about'], dtype='<U15'),\n",
       " array(['their', 'approach', 'used', 'to', 'train', 'Dolly', 'is', 'that',\n",
       "        'it', 'can', 'take', 'what', 'it', 'learned', 'from', 'a',\n",
       "        'variety', 'of', 'other', 'labeled', 'images', 'and', 'then',\n",
       "        'apply', 'it', 'to', 'a', 'new', 'image.', 'Given', 'a', 'picture',\n",
       "        'of', 'a', 'monkey,', 'Dolly', 'can', 'infer', 'what', 'it',\n",
       "        'would', 'look', 'like', 'doing', 'something', \"it's\", 'never',\n",
       "        'done', 'before,', 'like', 'paying', 'its', 'taxes', 'while',\n",
       "        'wearing', 'a', 'funny', 'hat.', 'Dolly', 'is', 'an', 'example',\n",
       "        'of', 'how', 'imaginative', 'humans', 'and', 'clever', 'systems',\n",
       "        'can', 'work', 'together', 'to', 'make', 'new', 'things,',\n",
       "        'amplifying', 'our', 'creative', 'potential.\"}'], dtype='<U15')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chunks = np.array_split(words, 6)\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"key\": \" Have you ever seen a polar bear playing bass? Or a robot painted like a Picasso? Didn\\'t think so. Dolly2 is a new AI system from OpenAI that can take simple text descriptions like a koala dunking a basketball and turn them into photo-realistic images that have never existed before. Dolly2 can also realistically edit and retouch photos. Based on a simple natural language description, it can fill in or replace part of an image with AI-generated imagery'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ' '.join(list(chunks[0]))\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full summary\n",
      ":\n",
      "\n",
      "OpenAI's Dolly2 is a new AI system that can take simple text descriptions and turn them into photo-realistic images that have never existed before. It can also realistically edit and retouch photos, filling in or replacing parts of an image with AI-generated imagery. OpenAI introduced Dolly2, a system that can generate images from text and also perform in-painting. It uses deep learning to create variations of an image with different angles and styles.\n",
      "\n",
      "Dolly is an AI that can create images of objects and their relationships. It helps people express themselves visually and can provide insights into how AI sees the world.: Dolly2 is an AI system that helps humans understand how AI systems see and interpret the world. It can be used to generate images based on user input, but it has limitations if it is taught with incorrectly labeled images.\n",
      "\n",
      "Dolly can generate great results if it has been trained with accurate labels and images, but may struggle to provide accurate results if it hasn't learned the correct word for something.: Dolly is an AI system that uses labeled images to create new images, amplifying our creative potential.\n"
     ]
    }
   ],
   "source": [
    "summary_responses = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    \n",
    "    sentences = ' '.join(list(chunk))\n",
    "\n",
    "    prompt = f\"{sentences}\\n\\n tl;dr\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\", \n",
    "        prompt=prompt,\n",
    "        temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
    "        max_tokens=150,\n",
    "        top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=1\n",
    "    )\n",
    "\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    summary_responses.append(response_text)\n",
    "\n",
    "full_summary = \"\".join(summary_responses)\n",
    "\n",
    "print(\"full summary\")\n",
    "print(full_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\":\\n\\nOpenAI's Dolly2 is a new AI system that can take simple text descriptions and turn them into photo-realistic images that have never existed before. It can also realistically edit and retouch photos, filling in or replacing parts of an image with AI-generated imagery. OpenAI introduced Dolly2, a system that can generate images from text and also perform in-painting. It uses deep learning to create variations of an image with different angles and styles.\\n\\nDolly is an AI that can create images of objects and their relationships. It helps people express themselves visually and can provide insights into how AI sees the world.: Dolly2 is an AI system that helps humans understand how AI systems see and interpret the world. It can be used to generate images based on user input, but it has limitations if it is taught with incorrectly labeled images.\\n\\nDolly can generate great results if it has been trained with accurate labels and images, but may struggle to provide accurate results if it hasn't learned the correct word for something.: Dolly is an AI system that uses labeled images to create new images, amplifying our creative potential.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "870720bd571c13f16a686dbc665ecdd76aedca7ba1c359741a90c7c02a4ae4aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
